<!DOCTYPE html><html><head>
      <title>实验报告</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\Thinkpad\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.13\crossnote\dependencies\katex\katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h2 id="center信息检索导论大作业-center"><center>信息检索导论大作业 </center> </h2>
<h4 id="center-llamaindex框架实现增强检索的足球私域知识对话模型-center"><center> ——LlamaIndex框架实现增强检索的足球私域知识对话模型 </center> </h4>
<h5 id="center-路欣艾--2021201226-luxinai_2003ruceducncenter"><center> 路欣艾  2021201226 <a href="mailto:luxinai_2003@ruc.edu.cn">luxinai_2003@ruc.edu.cn</a></center> </h5>
<h3 id="一--实验要求">一、 实验要求 </h3>
<p>以ChatGPT为代表的大语言模型（LLM）在自然语言理解和生成方面展现出强大的能力，检索增强生成 (Retrieval-Augmented Generation, RAG) 技术是指在利用大语言模型回答问题之前，先从外部知识源检索相关信息，提供给大语言模型，这让LLM可以充分利用外部知识资源生成更准确和更符合上下文的答案。</p>
<p>本项目要求使用<code>LlamaIndex</code>框架，基于大语言模型和检索增强生成技术，构建一个可以回答2024年足球新闻问题的系统。</p>
<p><img src="image.png" alt="alt text"></p>
<p>具体的要求包括：</p>
<blockquote>
<ul>
<li>数据集：使用给定的2024年足球新闻文章数据集<code>（data.csv）</code></li>
<li>基础RAG系统实现：使用<code>LlamaIndex</code>框架构建基本的RAG系统，包括索引、检索和生成步骤。</li>
<li>改进与优化：尝试不同的分块策略和大小、嵌入模型、多级索引、查询重写、混合检索和重新排序等方法来优化系统性能。</li>
<li>评估：设计实验评估基础和改进后的系统，提供性能指标和实例。</li>
</ul>
</blockquote>
<h3 id="二-实现思路">二、实现思路 </h3>
<h3 id="三-llamaindex基本对话模型">三、<code>LlamaIndex</code>基本对话模型 </h3>
<h4 id="1-openai-api">1. Openai API </h4>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> os
<span class="token keyword keyword-from">from</span> dotenv <span class="token keyword keyword-import">import</span> load_dotenv

OPENAI_API_KEY <span class="token operator">=</span> <span class="token string">'OPENAI_API_KEY'</span> 
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'OPENAI_API_KEY'</span> 

load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><h4 id="2-数据集准备">2. 数据集准备 </h4>
<p>读取<code>documents</code>，把文件用 <code>SimpleDirectoryReader</code> 方法存成 <code>documents</code>。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> os
<span class="token keyword keyword-import">import</span> gradio <span class="token keyword keyword-as">as</span> gr
<span class="token keyword keyword-import">import</span> openai

<span class="token keyword keyword-from">from</span> llama_index<span class="token punctuation">.</span>core <span class="token keyword keyword-import">import</span> VectorStoreIndex<span class="token punctuation">,</span>SimpleDirectoryReader<span class="token punctuation">,</span>
ServiceContext<span class="token punctuation">,</span>PromptTemplate
<span class="token keyword keyword-from">from</span> llama_index<span class="token punctuation">.</span>core<span class="token punctuation">.</span>schema <span class="token keyword keyword-import">import</span> IndexNode

<span class="token keyword keyword-from">from</span> llama_index<span class="token punctuation">.</span>core <span class="token keyword keyword-import">import</span> <span class="token punctuation">(</span>
    GPTKeywordTableIndex<span class="token punctuation">,</span>
    SimpleDirectoryReader<span class="token punctuation">,</span>
    ServiceContext
<span class="token punctuation">)</span>

documents <span class="token operator">=</span> SimpleDirectoryReader<span class="token punctuation">(</span>input_dir<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><h4 id="3-建立openaiembeddings索引">3. 建立<code>OpenAIEmbeddings</code>索引 </h4>
<p>采用最普通的索引方式<code>OpenAIEmbeddings</code>，这个过程会自动构建<code>documents</code>的<code>nodes</code>。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-from">from</span> llama_index<span class="token punctuation">.</span>core <span class="token keyword keyword-import">import</span> VectorStoreIndex<span class="token punctuation">,</span>DocumentSummaryIndex
<span class="token keyword keyword-from">from</span> langchain_openai <span class="token keyword keyword-import">import</span> OpenAIEmbeddings

<span class="token comment"># OpenAIEmbeddings()  </span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">"OpenAIEmbeddings:"</span><span class="token punctuation">)</span>
index_OpenAIEmbeddings <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents <span class="token operator">=</span> documents<span class="token punctuation">,</span>
 embedding <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> show_progress <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre><p>构建索引的过程：</p>
<p><img src="image-1.png" alt="alt text"></p>
<h4 id="4-rag检索引擎生成回复-get_responsequery">4. RAG检索引擎生成回复 <code>get_response(query)</code> </h4>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 这个位置可以替换不同的嵌入模型搞的引擎</span>
query_engine <span class="token operator">=</span> index_OpenAIEmbeddings<span class="token punctuation">.</span>as_chat_engine<span class="token punctuation">(</span>verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># get_response函数定义</span>
<span class="token keyword keyword-def">def</span> <span class="token function">get_response</span><span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">:</span>
    response <span class="token operator">=</span> query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span>query<span class="token punctuation">)</span>
    <span class="token keyword keyword-return">return</span> response
</code></pre><h4 id="5-gradio交互界面">5. <code>Gradio</code>交互界面 </h4>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> gradio <span class="token keyword keyword-as">as</span> gr
<span class="token keyword keyword-from">from</span> gradio<span class="token punctuation">.</span>components <span class="token keyword keyword-import">import</span> Textbox

<span class="token comment"># 创建Gradio界面</span>
iface <span class="token operator">=</span> gr<span class="token punctuation">.</span>Interface<span class="token punctuation">(</span>
    fn<span class="token operator">=</span>get_response<span class="token punctuation">,</span>
    inputs<span class="token operator">=</span>gr<span class="token punctuation">.</span>components<span class="token punctuation">.</span>Textbox<span class="token punctuation">(</span>lines<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"输入提示文本"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    outputs<span class="token operator">=</span><span class="token string">"text"</span><span class="token punctuation">,</span>
    title<span class="token operator">=</span><span class="token string">"小鹿的足球信息检索系统"</span><span class="token punctuation">,</span>
    description<span class="token operator">=</span><span class="token string">"使用 gpt-3.5 + 最新足球新闻的rag检索系统"</span>
<span class="token punctuation">)</span>

<span class="token comment"># 启动Gradio界面</span>
iface<span class="token punctuation">.</span>launch<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><p>【界面与问答效果】输入问题后，点击<code>Submit</code>按钮，提交用户的问题，引擎将增强检索后的回答输出在右侧<code>output</code>对话框中；用户可以通过点击<code>Flagged</code>将问题与引擎的答复保存在后端文件中；用户可以通过点击左侧<code>Clear</code>按钮将问题清空后重新提问。</p>
<p><img src="8abea2cac30f25fef7fb7a50b756e3e.png" alt="alt text"></p>
<h3 id="四-模型优化">四、模型优化 </h3>
<h4 id="1-两种不同huggingface嵌入模型">1. 两种不同<code>HuggingFace</code>嵌入模型 </h4>
<h5 id="1bge-large-zh-v15">（1）<code>bge-large-zh-v1.5</code> </h5>
<p><img src="image-2.png" alt="alt text"></p>
<p><img src="image-3.png" alt="alt text"></p>
<p>定义 <code>index_bge_large_zh</code>为使用该嵌入模型的索引名称。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># bge-large-zh-v1.5</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">"bge-large-zh-v1.5:"</span><span class="token punctuation">)</span>
bge_embeddings <span class="token operator">=</span> HuggingFaceBgeEmbeddings<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"BAAI/bge-large-zh-v1.5"</span><span class="token punctuation">)</span>
index_bge_large_zh <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents <span class="token operator">=</span> documents<span class="token punctuation">,</span> 
                embedding <span class="token operator">=</span> bge_embeddings<span class="token punctuation">,</span> show_progress <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre><p>生成<code>response</code>样例：</p>
<h5 id="2bge-m3">（2）<code>bge-M3</code> </h5>
<p><code>BGE-M3</code>是首个集多语言（Multi-Linguality）、多粒度（Multi-Granularity）、多功能（Multi-Functionality）三大技术特征于一体的语义向量模型，极大提升了语义向量模型在现实世界的可用性。目前，<code>BGE-M3</code>已向社区全面开源。</p>
<p>定义 <code>index_bge_M3</code>为使用该嵌入模型的索引名称。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># bge-M3</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">"bge-M3:"</span><span class="token punctuation">)</span>
bgeM3_embeddings <span class="token operator">=</span> HuggingFaceBgeEmbeddings<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"BAAI/bge-M3"</span><span class="token punctuation">)</span>
index_bge_M3 <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents <span class="token operator">=</span> documents<span class="token punctuation">,</span> 
                embedding <span class="token operator">=</span> bgeM3_embeddings<span class="token punctuation">,</span> show_progress <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre><p>生成<code>response</code>样例，可以看到，当询问的问题是“你是什么模型”时，增强后的引擎会加上足球相关的私域知识。</p>
<p><img src="image-4.png" alt="alt text"></p>
<h4 id="2-混合检索">2. 混合检索 </h4>
<h5 id="1-预处理文档集">(1) 预处理文档集 </h5>
<p>将<code>document</code>转换成可供<code>BM25Retriever</code>和<code>FAISS</code>对象使用<code>.from_texts()</code>初始化方法的格式<code>list</code></p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 定义空的文本列表</span>
doc_texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
splitted_texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment"># 遍历每个文档对象，获取文本内容和元数据</span>
<span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> doc <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> doc<span class="token punctuation">.</span>text  <span class="token comment"># text 属性用于获取文本内容</span>
    <span class="token keyword keyword-if">if</span> text<span class="token punctuation">:</span>
        doc_texts<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
        doc_texts<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>  <span class="token comment"># 如果文本内容为空，添加一个空字符串</span>

<span class="token comment"># 遍历每个文本内容，按照 "http" 进行分割</span>
<span class="token keyword keyword-for">for</span> text <span class="token keyword keyword-in">in</span> doc_texts<span class="token punctuation">:</span>
    <span class="token comment"># 使用 split 方法按照 "http" 进行分割，并加入到分割后的文本列表中</span>
    splitted_texts<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"http"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 将文档转换为文本列表和元数据列表</span>
doc_metadatas <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"source"</span><span class="token punctuation">:</span> i<span class="token punctuation">}</span> <span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>splitted_texts<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre><h5 id="2-定义稀疏检索bm25retriever和稠密检索faiss">(2) 定义稀疏检索<code>BM25Retriever</code>和稠密检索<code>FAISS</code> </h5>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 尝试混合检索方式</span>
<span class="token keyword keyword-from">from</span> langchain_community<span class="token punctuation">.</span>retrievers <span class="token keyword keyword-import">import</span> BM25Retriever
<span class="token keyword keyword-from">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword keyword-import">import</span> FAISS
<span class="token keyword keyword-from">from</span> langchain_openai <span class="token keyword keyword-import">import</span> OpenAIEmbeddings

<span class="token comment"># 初始化BM25检索器</span>
bm25_retriever <span class="token operator">=</span> BM25Retriever<span class="token punctuation">.</span>from_texts<span class="token punctuation">(</span>splitted_texts<span class="token punctuation">,</span> metadatas <span class="token operator">=</span> doc_metadatas<span class="token punctuation">)</span>
bm25_retriever<span class="token punctuation">.</span>k <span class="token operator">=</span> <span class="token number">3</span>

<span class="token comment"># 初始化FAISS检索器</span>
embedding <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
faiss_vectorstore <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>from_texts<span class="token punctuation">(</span>splitted_texts<span class="token punctuation">,</span> embedding<span class="token punctuation">,</span> metadatas<span class="token operator">=</span>doc_metadatas<span class="token punctuation">)</span>

<span class="token comment"># 将FAISS向量存储转化为检索器</span>
faiss_retriever <span class="token operator">=</span> faiss_vectorstore<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>search_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"k"</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

</code></pre><h5 id="3-定义混合检索ensembleretriever">(3) 定义混合检索<code>EnsembleRetriever</code> </h5>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 尝试混合检索方式</span>
<span class="token keyword keyword-from">from</span> langchain<span class="token punctuation">.</span>retrievers <span class="token keyword keyword-import">import</span> EnsembleRetriever
<span class="token keyword keyword-from">from</span> langchain_openai <span class="token keyword keyword-import">import</span> OpenAIEmbeddings

<span class="token comment"># 初始化Ensemble Retriever</span>
ensemble_retriever <span class="token operator">=</span> EnsembleRetriever<span class="token punctuation">(</span>
    retrievers<span class="token operator">=</span><span class="token punctuation">[</span>bm25_retriever<span class="token punctuation">,</span> faiss_retriever<span class="token punctuation">]</span><span class="token punctuation">,</span> weights<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>
</code></pre><h5 id="4-使用混合检索找到和问题相关的文档">(4) 使用混合检索，找到和问题相关的文档 </h5>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 使用Ensemble Retriever进行检索</span>
query <span class="token operator">=</span> <span class="token string">"曼联队员在3-0战胜西汉姆的比赛中都是怎样表现的？"</span>
docs <span class="token operator">=</span> ensemble_retriever<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>query<span class="token punctuation">)</span>

<span class="token keyword keyword-for">for</span> doc <span class="token keyword keyword-in">in</span> docs<span class="token punctuation">:</span>
    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Document ID: </span><span class="token interpolation"><span class="token punctuation">{</span>doc<span class="token punctuation">.</span>lc_id<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Content: </span><span class="token interpolation"><span class="token punctuation">{</span>doc<span class="token punctuation">.</span>page_content<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">"\n---\n"</span><span class="token punctuation">)</span>
</code></pre><p>查询到的相关文档：</p>
<p><img src="image-5.png" alt="alt text"></p>
<p><img src="image-6.png" alt="alt text"></p>
<h5 id="4-将混合检索结果与问题合并让引擎生成response">(4) 将混合检索结果与问题合并，让引擎生成<code>response</code> </h5>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 将相关文档内容组合成一个字符串，传递给query_engine</span>
doc_contents <span class="token operator">=</span> <span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>doc<span class="token punctuation">.</span>page_content <span class="token keyword keyword-for">for</span> doc <span class="token keyword keyword-in">in</span> docs<span class="token punctuation">]</span><span class="token punctuation">)</span>

combined_query <span class="token operator">=</span> f"我的问题是：<span class="token punctuation">{</span>query<span class="token punctuation">}</span>。我已知下面这些信息：<span class="token punctuation">{</span>doc_contents<span class="token punctuation">}</span>。
                                请你根据这些内容回答。"

<span class="token comment"># 使用query_engine进行总结和回答</span>
response <span class="token operator">=</span> query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span>combined_query<span class="token punctuation">)</span>

<span class="token comment"># 打印结果</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre><p>查询文本生成过程：
<img src="image-7.png" alt="alt text"></p>
<p>返回的<code>response</code>:</p>
<p><img src="image-8.png" alt="alt text"></p>
<blockquote>
<p>在曼联3-0战胜西汉姆的比赛中，曼联队员表现出色，他们成功取得胜利，拉什福德、Højlund和McTominay分别攻入进球。此外，拉什福德的表现引人注目，他在最近四场英超比赛中要么进球要么助攻。Højlund也状态良好，在过去五场比赛中在各项赛事中有六次进球参与。尽管存在一些防守问题，但球队能够派出强大的阵容，关键球员回归，他们成功取得了关键的胜利。而在这场比赛中，西汉姆队员并没有表现出色，因为在提到的情况下，实际比赛是西汉姆在伦敦体育场的反向比赛中以2-0获胜。</p>
</blockquote>
<h4 id="3-hyde查询重写">3. <code>HyDE</code>查询重写 </h4>
<p><code>HyDE</code>原理的核心思想是通过生成假设性文档来优化查询表示，从而提升检索结果的相关性和准确性。</p>
<p><img src="image-11.png" alt="alt text"></p>
<p>使用<code>HyDE</code>模型实现查询重写优化技术：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Hyde查询重写的结果</span>
<span class="token keyword keyword-from">from</span> llama_index<span class="token punctuation">.</span>core<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>query<span class="token punctuation">.</span>query_transform <span class="token keyword keyword-import">import</span> HyDEQueryTransform
<span class="token keyword keyword-from">from</span> llama_index<span class="token punctuation">.</span>core<span class="token punctuation">.</span>query_engine <span class="token keyword keyword-import">import</span> TransformQueryEngine

query_engine <span class="token operator">=</span> index_bge_M3<span class="token punctuation">.</span>as_chat_engine<span class="token punctuation">(</span>verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># hyde 查询重写</span>
hyde <span class="token operator">=</span> HyDEQueryTransform<span class="token punctuation">(</span>include_original<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
hyde_query_engine <span class="token operator">=</span> TransformQueryEngine<span class="token punctuation">(</span>query_engine<span class="token punctuation">,</span> hyde<span class="token punctuation">)</span>
response <span class="token operator">=</span> hyde_query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">"曼联队员在3-0战胜西汉姆的比赛中都是怎样表现的？"</span><span class="token punctuation">)</span>
</code></pre><p>是/否查询重写的<code>response</code>比较：</p>
<p><img src="image-9.png" alt="alt text"></p>
<p><code>response</code>的具体内容如下，似乎不能说有改善。</p>
<p>【Base Query】</p>
<blockquote>
<p>曼联队员在3-0战胜西汉姆的比赛中表现出色。拉什福德和霍伦德早早进球，麦克托米奈在下半场替补出场时攻入第三球。此外，科比·迈努在补时阶段打入一球，为曼联取得了胜利。</p>
</blockquote>
<p>【HyDE Query】</p>
<blockquote>
<p>曼联队员在3-0战胜西汉姆的比赛中表现出色，他们控制了比赛并创造了机会，拉什福德和Højlund早早进球。尽管有些防守问题，但他们成功地舒适地赢得了比赛。</p>
</blockquote>
<h3 id="五-使用deepeval对rag系统测试">五、使用<code>DeepEval</code>对RAG系统测试 </h3>
<h4 id="1-测试整体思路">1. 测试整体思路 </h4>
<p>测试一共要测试三种变量：哪种embedding、是否混合检索、是否查询重写，对这三个变量形成的组合进行5个指标的测评</p>
<ul>
<li>
<p><strong>测试embedding</strong><br>
<strong>控制变量</strong>:不混合检索、不查询重写 <br>
<strong>测试</strong>:更换index_OpenAIEmbeddings、index_bge_large_zh、index_bge_M3，看指标<br></p>
</li>
<li>
<p><strong>测试混合检索</strong> <br>
<strong>控制变量</strong>：使用index_OpenAIEmbeddings，不查询重写 <br>
<strong>测试</strong>：是否混合检索 <br></p>
</li>
<li>
<p><strong>测试查询重写</strong> <br>
<strong>控制变量</strong>：使用index_OpenAIEmbeddings，不混合检索 <br>
<strong>测试</strong>：是否查询重写 <br></p>
</li>
</ul>
<h4 id="2-测试数据集准备">2. 测试数据集准备 </h4>
<p>针对原始数据集中的新闻，本测试过程采用OpenAI公司的<code>gpt-4o</code>模型生成了20个细节问题和答案，其中，问题存为<code>questions</code>，答案存为<code>expected_outputs</code>。之所以选取20个问题，是因为openai的api接口在调用时有限额，且整个指标计算过程较慢，从经济成本和时间成本两方面考虑，本测试过程的问题集容量选取20较为合适。</p>
<p>问题集<code>query_new</code>:</p>
<blockquote>
<ul>
<li>在这次转会窗口，巴塞罗那计划如何处理财政问题以引进Amadou Onana？</li>
<li>Karim Benzema在沙特阿拉伯遇到了哪些问题，这对他和俱乐部有何影响？</li>
<li>曼联球员Lisandro Martinez受伤后，球队的战术和阵容发生了什么变化？</li>
<li>Ferran Torres在比赛中向一名癌症患者致敬，这对球员和球迷有何意义？</li>
<li>为什么Takehiro Tomiyasu在对阵West Ham United的比赛中缺席？他何时可能会重返阵容？</li>
<li>巴塞罗那被Villarreal重创后，他们与皇马的积分差多少？这对巴萨的联赛前景有何影响？</li>
<li>Cole Palmer在切尔西对阵水晶宫的比赛中表现出色，他提到了Mauricio Pochettino在胜利中的作用是什么？</li>
<li>在对阵阿斯顿维拉的比赛中，切尔西的球迷建议的终极阵容是什么？</li>
<li>在对阵托特纳姆热刺的比赛中，曼联球迷对马库斯·拉什福德的表现有什么意见？</li>
<li>吉安路易吉·布冯表示在他职业生涯中哪个前锋对他造成了最大的痛苦？</li>
<li>切尔西的蒂亚戈·席尔瓦在对阵水晶宫的比赛中做了什么冒险行为？</li>
<li>2023年斯坦福桥的比赛中，哪位球员在第71分钟进球使阿斯顿维拉战胜切尔西？</li>
<li>切尔西在2024年足总杯第三轮中以4-0战胜了哪支球队？</li>
<li>在2024年2月初对阵埃弗顿的比赛中，阿斯顿维拉取得了什么结果？</li>
<li>切尔西在2024年与阿斯顿维拉的比赛中，预计最有可能的比分是什么？</li>
<li>2024年利物浦对阵阿森纳的比赛中，克洛普是否对达尔文·努涅斯不上场感到后悔？</li>
<li>克洛普在2024年对阵阿森纳的比赛中，提到球队应该如何提高？</li>
<li>康纳·加拉格尔在2024年对阵水晶宫的比赛中打进了多少球？</li>
<li>康纳·加拉格尔在对阵水晶宫的比赛中，被评为比赛最佳球员后提到了什么关于主教练的战术调整？</li>
<li>梅西、苏亚雷斯、阿尔巴和布斯克茨在2024年为哪支球队展示了他们的出色配合？</li>
</ul>
</blockquote>
<p>答案集<code>expected_output</code>（数据类型为<code>list</code>）：</p>
<blockquote>
<ul>
<li>巴塞罗那计划通过出售一些球员来筹集资金，可能会将Frenkie De Jong和Ronald Araujo列入出售名单，以便购买Amadou Onana。</li>
<li>Karim Benzema与Al Ittihad的主教练Marcelo Gallardo发生了冲突，这可能对他在俱乐部的未来产生影响，并可能影响球队的氛围和战绩。</li>
<li>Lisandro Martinez受伤后，曼联可能需要调整他们的防守组织和中场配置，可能会影响他们在比赛中的表现和战术风格。</li>
<li>Ferran Torres的这个举动展现了他的人道主义精神和对球迷的关怀，这可能会赢得更多球迷的支持和尊重，同时也为球迷带来了温暖和鼓舞。</li>
<li>Takehiro Tomiyasu因为国家队比赛后出现了小伤，所以缺席了比赛。目前尚不清楚他何时可以重返阵容，但希望他的伤势只是轻微的问题。</li>
<li>巴塞罗那在主场被Villarreal以5-3击败，导致他们与皇马的积分差距达到了10分。这对巴萨本赛季的联赛前景造成了不小的影响，使得他们的冠军希望受到挑战。</li>
<li>Cole Palmer提到了Mauricio Pochettino在胜利中的作用，称赞了他的指导和支持，认为Pochettino对球队的凝聚力和信心给予了很大的帮助。这表明了Pochettino在切尔西的作用和影响。</li>
<li>Petrovic；迪萨西、蒂亚戈·席尔瓦、巴迪亚希尔；奇尔维尔、凯塞多、恩佐、古斯托；帕尔默、杰克逊、恩昆库。</li>
<li>尽管拉什福德打入一球，但有一部分球迷对他的表现不满意，认为他决策糟糕，影响了球队进攻。有球迷甚至呼吁曼联在夏季将他出售。</li>
<li>布冯表示是克里斯蒂亚诺·罗纳尔多，总是能在比赛中攻破他的球门，尤其是2018年欧冠四分之一决赛中的倒钩进球。</li>
<li>蒂亚戈·席尔瓦冒着受伤的风险，封堵了马特塔的一次射门，但在此过程中脚踝扭伤，被利维·科尔威尔替换下场。</li>
<li>奥利·沃特金斯 (Ollie Watkins)</li>
<li>普雷斯顿北区 (Preston North End)</li>
<li>平局</li>
<li>1-1</li>
<li>克洛普表示他不会改变首发阵容，但在比赛后可能会有不同的想法。</li>
<li>克洛普认为球队需要踢得更好，并在接下来的比赛中展现出更好的足球水平。</li>
<li>两个</li>
<li>主教练在中场休息时改变了球队在对方半场的结构，使球队在下半场创造了更多机会。</li>
<li>迈阿密国际</li>
</ul>
</blockquote>
<h4 id="2-deepeval评估指标选取">2. <code>DeepEval</code>评估指标选取 </h4>
<h5 id="1g-eval">（1）<code>G-Eval</code> </h5>
<p>官方文档对<code>G-Eval</code>指标的描述：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>correctness_metric <span class="token operator">=</span> GEval<span class="token punctuation">(</span>
    name<span class="token operator">=</span><span class="token string">"Correctness"</span><span class="token punctuation">,</span>
    criteria<span class="token operator">=</span><span class="token string">"Determine whether the actual output is factually"</span><span class="token operator">+</span>
    <span class="token string">"correct based on the expected output."</span><span class="token punctuation">,</span>
    <span class="token comment"># NOTE: you can only provide either criteria or evaluation_steps, and not both</span>
    evaluation_steps<span class="token operator">=</span><span class="token punctuation">[</span>
        <span class="token string">"Check whether the facts in 'actual output' contradicts "</span> <span class="token operator">+</span> 
        <span class="token string">"any facts in 'expected output'"</span><span class="token punctuation">,</span>
        <span class="token string">"You should also heavily penalize omission of detail"</span><span class="token punctuation">,</span>
        <span class="token string">"Vague language, or contradicting OPINIONS, are OK"</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    evaluation_params<span class="token operator">=</span><span class="token punctuation">[</span>LLMTestCaseParams<span class="token punctuation">.</span>INPUT<span class="token punctuation">,</span> LLMTestCaseParams<span class="token punctuation">.</span>ACTUAL_OUTPUT<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre><p>定义<code>G-Eval</code>矩阵：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 引入评估指标1：G评估</span>
<span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>metrics <span class="token keyword keyword-import">import</span> GEval
<span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>test_case <span class="token keyword keyword-import">import</span> LLMTestCaseParams
<span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>test_case <span class="token keyword keyword-import">import</span> LLMTestCase

correctness_metric <span class="token operator">=</span> GEval<span class="token punctuation">(</span>
    name<span class="token operator">=</span><span class="token string">"Correctness"</span><span class="token punctuation">,</span>
    model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">,</span>
    criteria<span class="token operator">=</span><span class="token string">"Determine whether the actual output is factually correct"</span> <span class="token operator">+</span> 
    <span class="token string">" based on the expected output."</span><span class="token punctuation">,</span>
    evaluation_params<span class="token operator">=</span><span class="token punctuation">[</span>LLMTestCaseParams<span class="token punctuation">.</span>INPUT<span class="token punctuation">,</span> LLMTestCaseParams<span class="token punctuation">.</span>ACTUAL_OUTPUT<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre><h5 id="2answer-relevancy">（2）<code>Answer Relevancy</code> </h5>
<p>官方文档对<code>Answer Relevancy</code>指标的描述：</p>
<blockquote>
<p>The answer relevancy metric measures the quality of your RAG pipeline's generator by evaluating how relevant the <code>actual_output </code>of your LLM application is compared to the provided <code>input</code>. deepeval's answer relevancy metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score.</p>
</blockquote>
<p>计算方法：
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>n</mi><mi>s</mi><mi>w</mi><mi>e</mi><mi>r</mi><mi>R</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>R</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>t</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow><mrow><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Answer Relevancy= \frac{Number of Relevant Statements}{Total Number of Statements}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal" style="margin-right:0.02778em;">er</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">an</span><span class="mord mathnormal" style="margin-right:0.03588em;">cy</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2519em;vertical-align:-0.8804em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10903em;">lN</span><span class="mord mathnormal">u</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">ero</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">St</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">u</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">ero</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">an</span><span class="mord mathnormal">tSt</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>定义<code>Answer Relevancy</code>矩阵：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 引入评估指标2：答案相关性</span>
<span class="token keyword keyword-from">from</span> deepeval <span class="token keyword keyword-import">import</span> evaluate
<span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>metrics <span class="token keyword keyword-import">import</span> AnswerRelevancyMetric
<span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>test_case <span class="token keyword keyword-import">import</span> LLMTestCase

Relevancy_metric <span class="token operator">=</span> AnswerRelevancyMetric<span class="token punctuation">(</span>
    threshold<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">,</span>
    model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">,</span>
    include_reason<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
</code></pre><h5 id="3contextual-relevancy">（3）<code>Contextual Relevancy</code> </h5>
<p>官方文档对<code>Contextual Relevancy</code>指标的描述：</p>
<blockquote>
<p>The contextual relevancy metric measures the quality of your RAG pipeline's retriever by evaluating the overall relevance of the information presented in your <code>retrieval_context</code> for a given <code>input</code>. deepeval's contextual relevancy metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score.</p>
</blockquote>
<p>计算方法：
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi><mi>R</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>R</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>t</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow><mrow><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>s</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Contextual Relevancy= \frac{Number of Relevant Statements}{Total Number of Statements}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.00773em;">lR</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">an</span><span class="mord mathnormal" style="margin-right:0.03588em;">cy</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2519em;vertical-align:-0.8804em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10903em;">lN</span><span class="mord mathnormal">u</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">ero</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">St</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">u</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">ero</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">an</span><span class="mord mathnormal">tSt</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
​
定义<code>Contextual Relevancy</code>矩阵：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-from">from</span> deepeval <span class="token keyword keyword-import">import</span> evaluate
<span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>metrics <span class="token keyword keyword-import">import</span> ContextualRelevancyMetric
<span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>test_case <span class="token keyword keyword-import">import</span> LLMTestCase


ContextualRelevancy_metric <span class="token operator">=</span> ContextualRelevancyMetric<span class="token punctuation">(</span>
    threshold<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">,</span>
    model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">,</span>
    include_reason<span class="token operator">=</span><span class="token number">0</span>
<span class="token punctuation">)</span>
</code></pre><h5 id="4hallucination幻觉">（4）<code>Hallucination</code>（幻觉） </h5>
<p>官方文档对<code>Hallucination</code>指标的描述：</p>
<blockquote>
<p>The hallucination metric determines whether your LLM generates factually correct information by comparing the <code>actual_output</code> to the <code>provided context</code>.</p>
</blockquote>
<p>计算方法：
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>​</mtext><mi>H</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>u</mi><mi>c</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>e</mi><mi>d</mi><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>s</mi></mrow><mrow><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>N</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>C</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>s</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">​Hallucination= \frac{Number of Contradicted Contexts}{Total Number of Contexts}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">​</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">ll</span><span class="mord mathnormal">u</span><span class="mord mathnormal">c</span><span class="mord mathnormal">ina</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2519em;vertical-align:-0.8804em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.10903em;">lN</span><span class="mord mathnormal">u</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">ero</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">u</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">ero</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
​
定义<code>Contextual Relevancy</code>矩阵：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>metrics <span class="token keyword keyword-import">import</span> HallucinationMetric

Hallucination_metric <span class="token operator">=</span> HallucinationMetric<span class="token punctuation">(</span>threshold<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>
</code></pre><h4 id="3-customllm-定义">3. CustomLLM 定义 </h4>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> gradio <span class="token keyword keyword-as">as</span> gr
<span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>models<span class="token punctuation">.</span>base_model <span class="token keyword keyword-import">import</span> DeepEvalBaseLLM

<span class="token comment"># 定义自定义模型</span>
<span class="token keyword keyword-class">class</span> <span class="token class-name">CustomLLM</span><span class="token punctuation">(</span>DeepEvalBaseLLM<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query_engine<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>query_engine <span class="token operator">=</span> query_engine

    <span class="token keyword keyword-def">def</span> <span class="token function">load_model</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>query_engine

    <span class="token keyword keyword-def">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> prompt<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>
        response <span class="token operator">=</span> self<span class="token punctuation">.</span>query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
        <span class="token keyword keyword-return">return</span> response
    
    <span class="token keyword keyword-def">def</span> <span class="token function">query</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> prompt<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>
        response <span class="token operator">=</span> self<span class="token punctuation">.</span>query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
        <span class="token keyword keyword-return">return</span> response

    <span class="token keyword keyword-async">async</span> <span class="token keyword keyword-def">def</span> <span class="token function">a_generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> prompt<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
    
    <span class="token keyword keyword-def">def</span> <span class="token function">get_model_name</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-return">return</span> <span class="token string">"Custom OpenAI Embedding Model"</span>
</code></pre><h4 id="4-测试三种索引下的模型">4. 测试三种索引下的模型 </h4>
<h5 id="1建立索引">（1）建立索引 </h5>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-from">from</span> llama_index<span class="token punctuation">.</span>core <span class="token keyword keyword-import">import</span> VectorStoreIndex<span class="token punctuation">,</span>DocumentSummaryIndex
<span class="token comment"># from haystack.indexing.vector_store import VectorStoreIndex</span>
<span class="token keyword keyword-from">from</span> llama_index<span class="token punctuation">.</span>core <span class="token keyword keyword-import">import</span> KnowledgeGraphIndex
<span class="token keyword keyword-from">from</span> langchain<span class="token punctuation">.</span>vectorstores <span class="token keyword keyword-import">import</span> FAISS
<span class="token keyword keyword-from">from</span> langchain_openai <span class="token keyword keyword-import">import</span> OpenAIEmbeddings

<span class="token comment"># OpenAIEmbeddings()  </span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">"OpenAIEmbeddings:"</span><span class="token punctuation">)</span>
index_OpenAIEmbeddings <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents <span class="token operator">=</span> documents<span class="token punctuation">,</span> 
StorageContext <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> embedding <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> show_progress <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword keyword-from">from</span> langchain<span class="token punctuation">.</span>embeddings <span class="token keyword keyword-import">import</span> HuggingFaceBgeEmbeddings

<span class="token comment"># bge-large-zh-v1.5</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">"bge-large-zh-v1.5:"</span><span class="token punctuation">)</span>
bge_embeddings <span class="token operator">=</span> HuggingFaceBgeEmbeddings<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"BAAI/bge-large-zh-v1.5"</span><span class="token punctuation">)</span>
index_bge_large_zh <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>
  documents <span class="token operator">=</span> documents<span class="token punctuation">,</span> embedding <span class="token operator">=</span> bge_embeddings<span class="token punctuation">,</span> show_progress <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># bge-M3</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">"bge-M3:"</span><span class="token punctuation">)</span>
bgeM3_embeddings <span class="token operator">=</span> HuggingFaceBgeEmbeddings<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"BAAI/bge-M3"</span><span class="token punctuation">)</span>
index_bge_M3 <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents <span class="token operator">=</span> documents<span class="token punctuation">,</span> 
embedding <span class="token operator">=</span> bgeM3_embeddings<span class="token punctuation">,</span> show_progress <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre><h5 id="2定义evaluate_responses测试函数">（2）定义<code>evaluate_responses</code>测试函数 </h5>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 准备函数retrieval_context(nodes_r)，用来返回、拼接检索到的文档内容</span>
<span class="token keyword keyword-def">def</span> <span class="token function">retrieval_context</span><span class="token punctuation">(</span>nodes_r<span class="token punctuation">)</span><span class="token punctuation">:</span>
    context_template <span class="token operator">=</span> <span class="token string">" "</span>
    context_ls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword keyword-for">for</span> node_r <span class="token keyword keyword-in">in</span> nodes_r<span class="token punctuation">:</span>
        context_template <span class="token operator">=</span> context_template <span class="token operator">+</span> node_r<span class="token punctuation">.</span>text<span class="token operator">+</span><span class="token string">"\n"</span>
        context_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>node_r<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
        
    <span class="token keyword keyword-return">return</span> context_template<span class="token punctuation">,</span>context_ls
</code></pre><pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>metrics <span class="token keyword keyword-import">import</span> ToxicityMetric
<span class="token keyword keyword-from">from</span> deepeval<span class="token punctuation">.</span>test_case <span class="token keyword keyword-import">import</span> LLMTestCase

<span class="token keyword keyword-def">def</span> <span class="token function">evaluate_responses</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> questions<span class="token punctuation">,</span> expected_outputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword keyword-assert">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>questions<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>expected_outputs<span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token string">"questions 和 expected_outputs 列表长度不一致"</span>
    
    <span class="token comment"># 调用上面矩阵来求各个评估指标</span>
    Correctness <span class="token operator">=</span> correctness_metric
    Summarization <span class="token operator">=</span> Summarization_metric
    Relevancy <span class="token operator">=</span> Relevancy_metric
    ContextualRelevancy <span class="token operator">=</span> ContextualRelevancy_metric
    Hallucination <span class="token operator">=</span> Hallucination_metric
    
    results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> question <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>questions<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 生成 response</span>
        response <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>question<span class="token punctuation">)</span>
        
        <span class="token comment"># 求context内容</span>
        retriever_base <span class="token operator">=</span> index_OpenAIEmbeddings<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>similarity_top_k<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
        nodes_r <span class="token operator">=</span> retriever_base<span class="token punctuation">.</span>retrieve<span class="token punctuation">(</span>question<span class="token punctuation">)</span>
        context<span class="token punctuation">,</span>context_ls <span class="token operator">=</span> retrieval_context<span class="token punctuation">(</span>nodes_r<span class="token punctuation">)</span>
        
        <span class="token comment"># 求对应 expected_output</span>
        expected_output <span class="token operator">=</span> expected_outputs<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        
        <span class="token comment"># 求各种指标</span>
        test_case <span class="token operator">=</span> LLMTestCase<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>question<span class="token punctuation">,</span> actual_output<span class="token operator">=</span>response<span class="token punctuation">,</span> 
                                retrieval_context<span class="token operator">=</span>context_ls<span class="token punctuation">,</span> context <span class="token operator">=</span> context_ls<span class="token punctuation">,</span> 
                                expected_output<span class="token operator">=</span>expected_output<span class="token punctuation">)</span>
        Correctness<span class="token punctuation">.</span>measure<span class="token punctuation">(</span>test_case<span class="token punctuation">)</span>
        Summarization<span class="token punctuation">.</span>measure<span class="token punctuation">(</span>test_case<span class="token punctuation">)</span>
        Relevancy<span class="token punctuation">.</span>measure<span class="token punctuation">(</span>test_case<span class="token punctuation">)</span>
        ContextualRelevancy<span class="token punctuation">.</span>measure<span class="token punctuation">(</span>test_case<span class="token punctuation">)</span>
        Hallucination<span class="token punctuation">.</span>measure<span class="token punctuation">(</span>test_case<span class="token punctuation">)</span>
    
        <span class="token comment"># 生成result</span>
        results<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span>
            <span class="token string">'question'</span><span class="token punctuation">:</span> question<span class="token punctuation">,</span>
            <span class="token string">'response'</span><span class="token punctuation">:</span> response<span class="token punctuation">,</span>
            <span class="token string">'Correctness'</span><span class="token punctuation">:</span> Correctness<span class="token punctuation">.</span>score<span class="token punctuation">,</span>
            <span class="token string">'Summarization'</span><span class="token punctuation">:</span> Summarization<span class="token punctuation">.</span>score<span class="token punctuation">,</span>
            <span class="token string">'Relevancy'</span><span class="token punctuation">:</span> Relevancy<span class="token punctuation">.</span>score<span class="token punctuation">,</span>
            <span class="token string">'ContextualRelevancy'</span><span class="token punctuation">:</span> ContextualRelevancy<span class="token punctuation">.</span>score<span class="token punctuation">,</span>
            <span class="token string">'Hallucination'</span><span class="token punctuation">:</span> Hallucination<span class="token punctuation">.</span>score<span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
        
    <span class="token keyword keyword-return">return</span> results
</code></pre><h5 id="3调用evaluate_responses测试并将结果写入文件">（3）调用<code>evaluate_responses</code>测试，并将结果写入文件 </h5>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 初始化emb1_llm</span>
emb1_engine <span class="token operator">=</span> index_OpenAIEmbeddings<span class="token punctuation">.</span>as_chat_engine<span class="token punctuation">(</span>verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
index_OpenAIEmbeddings<span class="token punctuation">.</span>storage_context
emb1_llm <span class="token operator">=</span> CustomLLM<span class="token punctuation">(</span>query_engine<span class="token operator">=</span>emb1_engine<span class="token punctuation">)</span>

<span class="token comment"># 初始化emb2_llm</span>
emb2_engine <span class="token operator">=</span> index_bge_large_zh<span class="token punctuation">.</span>as_chat_engine<span class="token punctuation">(</span>verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
index_bge_large_zh<span class="token punctuation">.</span>storage_context
emb2_llm <span class="token operator">=</span> CustomLLM<span class="token punctuation">(</span>query_engine<span class="token operator">=</span>emb2_engine<span class="token punctuation">)</span>

<span class="token comment"># 初始化emb3_llm</span>
emb3_engine <span class="token operator">=</span> index_bge_M3<span class="token punctuation">.</span>as_chat_engine<span class="token punctuation">(</span>verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
index_bge_M3<span class="token punctuation">.</span>storage_context
emb3_llm <span class="token operator">=</span> CustomLLM<span class="token punctuation">(</span>query_engine<span class="token operator">=</span>emb3_engine<span class="token punctuation">)</span>
</code></pre><pre data-role="codeBlock" data-info="python" class="language-python python"><code>results_emb1 <span class="token operator">=</span> evaluate_responses<span class="token punctuation">(</span>emb1_llm<span class="token punctuation">,</span> questions<span class="token punctuation">,</span> expected_output<span class="token punctuation">)</span>
results_emb2 <span class="token operator">=</span> evaluate_responses<span class="token punctuation">(</span>emb2_llm<span class="token punctuation">,</span> questions<span class="token punctuation">,</span> expected_output<span class="token punctuation">)</span>
results_emb3 <span class="token operator">=</span> evaluate_responses<span class="token punctuation">(</span>emb3_llm<span class="token punctuation">,</span> questions<span class="token punctuation">,</span> expected_output<span class="token punctuation">)</span>
</code></pre><p>得到result如下：</p>
<p><img src="image-13.png" alt="alt text"></p>
<h4 id="5-测试混合检索模型">5. 测试混合检索模型 </h4>
<h5 id="1调用之前-bm25faiss-的混合检索器">（1）调用之前 BM25+FAISS 的混合检索器 </h5>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 初始化Ensemble Retriever</span>
ensemble_retriever <span class="token operator">=</span> EnsembleRetriever<span class="token punctuation">(</span>
    retrievers<span class="token operator">=</span><span class="token punctuation">[</span>bm25_retriever<span class="token punctuation">,</span> faiss_retriever<span class="token punctuation">]</span><span class="token punctuation">,</span> weights<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>
</code></pre><h5 id="2调用evaluate_responses_ensemble测试并将结果写入文件">（2）调用<code>evaluate_responses_ensemble</code>测试，并将结果写入文件 </h5>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>result_ensemble <span class="token operator">=</span> evaluate_responses_ensemble<span class="token punctuation">(</span>
          emb1_llm<span class="token punctuation">,</span> questions<span class="token punctuation">,</span> ensemble_retriever<span class="token punctuation">,</span> expected_output<span class="token punctuation">)</span>
</code></pre><p><img src="image-14.png" alt=""></p>
<h4 id="6-测试hyde查询重写">6. 测试HyDE查询重写 </h4>
<h5 id="1调用evaluate_responses_hyde测试并将结果写入文件">（1）调用<code>evaluate_responses_hyde</code>测试，并将结果写入文件 </h5>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>result_hyde <span class="token operator">=</span> evaluate_responses_hyde<span class="token punctuation">(</span>emb1_llm<span class="token punctuation">,</span> questions<span class="token punctuation">,</span>expected_output<span class="token punctuation">)</span>
</code></pre><p><img src="image-15.png" alt="alt text"></p>
<h3 id="六-测试结果">六、测试结果 </h3>
<h4 id="1-整体结果展示">1. 整体结果展示 </h4>
<p>可以看到 ，模型在整体准确度和与问题的相关性、逻辑性（前后无矛盾）方面表现较好。对于大部分新闻内的细节问题，都能够准确作答。</p>
<table>
<thead>
<tr>
<th></th>
<th>Correctness</th>
<th>Relevancy</th>
<th>Contextual Relevancy</th>
<th>Hallucination</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OpenAIEmbeddings</strong></td>
<td>0.7699</td>
<td>0.9650</td>
<td>0.1400</td>
<td>0.9829</td>
</tr>
<tr>
<td><strong>bge-large-zh-v1.5</strong></td>
<td>0.7235</td>
<td>0.9025</td>
<td>0.1600</td>
<td>0.8900</td>
</tr>
<tr>
<td><strong>bge-M3</strong></td>
<td>0.7403</td>
<td>0.8148</td>
<td>0.2222</td>
<td>0.9444</td>
</tr>
<tr>
<td><strong>ensemble</strong></td>
<td>0.6528</td>
<td>0.7600</td>
<td>0.1550</td>
<td>0.8800</td>
</tr>
<tr>
<td><strong>HyDE</strong></td>
<td>0.6877</td>
<td>1.0000</td>
<td>0.2778</td>
<td>0.9619</td>
</tr>
</tbody>
</table>
<p><img src="image-24.png" alt="alt text"></p>
<h4 id="2-三种嵌入模型效果">2. 三种嵌入模型效果 </h4>
<p>OpenAIEmbeddings整体表现最优。</p>
<p><img src="image-21.png" alt="alt text"></p>
<h4 id="3-混合检索效果">3. 混合检索效果 </h4>
<p>可以看到混合检索效果不佳，并不符合预期。猜想可能的原因有：检索模型的组合和权重可能欠考虑；检索返回的文档数目不合理，导致LLM在生成答案时受到影响等。</p>
<p><img src="image-22.png" alt="alt text"></p>
<h4 id="4-查询重写效果">4. 查询重写效果 </h4>
<p>可以看出，使用查询重写后，比base的嵌入的engine的correctness下降了，relevance指标有所上升。分析原因，可能是由于查询重写的过程涉及生成与原始查询相关的假设性文档，扩展了查询的语义范围，捕捉到更多潜在的相关信息。这种语义扩展能够提升relevance指标，因为更多的相关文档被纳入了检索范围。但是这种扩展也可能引入一些与查询不完全匹配的文档，导致correctness下降。</p>
<p><img src="image-23.png" alt="alt text"></p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>